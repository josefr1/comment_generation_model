# -*- coding: utf-8 -*-
"""responsive_image_comment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rrNwiw0544htuovUaM8ei_bugVeiz0pZ
"""

#!pip install transformers torch
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import login
import random
import re
import time
from transformers import pipeline

login(token="insert token here")

"""## Responsive Chat Model


---


#### The following script uses the meta llama-3.2-3B-Instruct text generation model to create a comment based on a topic and optional previous comment. The previous comment allows the model to create a more personalized message(i.e. responding to a message) however it can also create a new message just based off the topic.


---


#### Below are key details about the functions currently used, including their compute time and recommendations for applications.

"""

model_name = "meta-llama/llama-3.2-3B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")

"""### Pipeline Details
#### **Models Used:**
* text generation: meta-lama/llama-3.2-3B-Instruct
* image-to-text generation: Salesforce blip-image-captioning-base

#### **Functions**


---


**1. create_prompt() --> Prompt for the comment generation model**

Input Params
* string: title
* list: username_list
* string: description
* string: image_description
* string(optional): previous_comment

Output
* string: base_prompt

---
**2. is_valid_message() --> Checks if output of comment is correct**

Input Params
* string: message

Output
* boolean: True/False
---
**3. generate_message() --> Runs text generation model and returns the comment**

Input Params
* string: title
* list: username_list
* string(optional): previous_comment

Output
* string: comment



---
**4. image_to_text() --> Runs image generation model and returns the description of the image**

Input Params
* string: image(png/jpg work)

Output
* string: comment


---
**5. Time Cost:**
* CPU: ~300s
* GPU - T4: ~1.1s
---
"""

#another potential pipeline model although it didnt perform as well: model="nlpconnect/vit-gpt2-image-captioning"

def image_to_text(image):
  model = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
  output = model(image)
  description = output[0]['generated_text']
  return description

def create_prompt(title, username_list, description, image_description, previous_comment=None):
    # Handle previous comment section
    if previous_comment:
        previous_section = f"The previous comment from another user was:\n{previous_comment}\nWrite a comment that either reacts to this, adds context, agrees, lightly critiques, or shares a different perspective in a friendly way."
    else:
        previous_section = "Write a standalone comment about the topic and/or the image."

    # Main prompt with positivity bias
    base_prompt = f"""
You are generating a single **comment** from a random user on a comment section (like YouTube or TikTok) for the topic **{game_title}**.
Choose the username **ONLY** from this list: {username_list}.

The topic description is:
\"\"\"{game_description}\"\"\"

The current image shows:
\"\"\"{image_description}\"\"\"

Comments may talk about the topic, the image, or both.

**Comment Style Guidelines (choose one style at random):**
- Share excitement, enthusiasm, or positive reactions about the game or the image.
- Compliment the game's visuals, mechanics, soundtrack, or style.
- Ask a friendly question or express curiosity.
- Share a personal experience or fun memory related to the topic.
- Lightly critique or offer suggestions, but keep the tone respectful, balanced, or constructive (e.g., “I wish there were more levels like this!” or “It’s fun, though the controls can feel a bit tricky sometimes.”).
- Use playful or humorous comments that feel natural in a social media comment section.

**Avoid full negativity, harsh criticism, or toxic comments. Critique is allowed only if it feels fair, balanced, or framed politely.**

{previous_section}

**IMPORTANT INSTRUCTIONS:**
- Output MUST be in the exact format:
  Username: Comment
- Do NOT include quotes, brackets, bullet points, or any extra formatting.
- Do NOT include explanations, prefaces, or any additional text.
- Write the comment naturally, like a real person posting in a comment section.

**EXAMPLE OUTPUT (format only, content will change):**
mushroomDash: Yeah I agree. The stunts in this video are awesome!

Now, generate exactly ONE comment.
Output ONLY the comment in the format: Username: Comment
"""
    return base_prompt


def is_valid_message(message):
    """Check if the message follows the correct format"""
    # Basic format check
    if not ': ' in message:
        return False

    # Split into username and message
    parts = message.split(': ', 1)
    if len(parts) != 2:
        return False

    username, content = parts

    # Username checks
    if len(username) < 3 or len(username) > 30:  # reasonable username length
        return False
    if 'user' in username.lower():  # avoid generic usernames
        return False

    # Message content checks
    if len(content) < 10 or len(content) > 200:  # reasonable message length
        return False

    return True

def generate_message(title, username_list, description, image_description, previous_comment=None):
    start_time = time.time()
    try:
        inputs = tokenizer(create_prompt(title, username_list, description, image_description, previous_comment), return_tensors="pt", truncation=True).to(model.device)

        outputs = model.generate(
            **inputs,
            max_new_tokens=50,
            do_sample=True,
            temperature=0.95,
            top_p=0.95,
            no_repeat_ngram_size=3,
            pad_token_id=tokenizer.eos_token_id
        )

        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        messages = [line.strip() for line in generated_text.split('\n') if ': ' in line]

        if messages:
            message = messages[-1]
            if is_valid_message(message):
                elapsed = time.time() - start_time
                print(f"time taken: {elapsed}")
                return message

    except Exception as e:
        print("Failed:", e)
    elapsed = time.time() - start_time
    print(f"time taken: {elapsed}")
    return None

result = generate_message(
    title="Mario Run",
    username_list=["player1", "player2", "player3"],
    description = """
Mario is running for life, help!

1. Mario is on the run from Bowser's minions and needs your help to reach the castle safely.
2. Use your quick reflexes to dodge obstacles and enemies as Mario runs through the Mushroom Kingdom.
3. Collect power-ups and coins to help Mario defeat Bowser and save Princess Peach.
4. The game features colorful and vibrant graphics, with detailed environments and characters.
5. Mario can jump, dash, and stomp his way through the game's various levels.
6. Each level presents a new challenge, with increasing difficulty and more enemies to defeat.
7. Players can compete with friends and other players from around the world to see who can reach the highest score.
8. With intuitive controls and a simple, yet addictive gameplay, Mario On The Run is easy to pick up but hard to put down.
9. The game features a variety of power-ups, including mushrooms, fire flowers, and stars, which give Mario new abilities and powers.
10. With its fast-paced action, colorful graphics, and addictive gameplay, Mario On The Run is the perfect game for players of all ages and skill levels.
""",
    image_description=image_to_text("mario_test.png"),
    previous_comment="this game sucks im never playing it again"
    )

result

